{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6230f66f-e894-48e5-ba57-e65a0127a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your ANTHROPIC API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Enter your key\n",
    "key = getpass.getpass('Enter your ANTHROPIC API key: ')\n",
    "\n",
    "# Set the environment variable without displaying the full key\n",
    "os.environ['ANTHROPIC_API_KEY'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053a240e-45a5-4a17-882f-2810921c2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2343e5b2-9814-439a-b33d-2859d1fb2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter Distributed extension with persistent processes loaded.\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf632e48-8a6a-4df8-90eb-cdbc4b3c870f",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23041bc-08d4-46e6-970f-ea1946576985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173f9c95-1dfe-4546-86c1-911b458b3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data-ops/datasets/downloads/livecodebench-code_generation_lite--main-test6.jsonl\"\n",
    "dset = load_dataset(\"json\", data_files=data_path)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab80ef0-8045-4d63-ad40-4b75994313ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a helpful and harmless assistant.\"\n",
    "prompt_template = \"\"\"Write python code to solve the following problem:\n",
    "\n",
    "{question_content}\n",
    "\n",
    "Your solution should follow the format\n",
    "\n",
    "```python\n",
    "{starter_code}...\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab1fcb-c50b-4368-9c6f-3d51022f6d16",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04783e76-31f1-409c-ab32-ad41fc35a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 1.39 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "import torch.distributed as dist\n",
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8af6c3-c390-4110-9cb0-8a948f9b6663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 2.96 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "WORLD_SIZE = 8\n",
    "RANK = __process_id__\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch.distributed as dist\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "os.environ['LOCAL_RANK'] = str(RANK)\n",
    "dist.init_process_group('nccl', rank=RANK, world_size=WORLD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14375ee4-dc25-4a34-bfae-34b87f7b59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "[Process 6] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 0] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 4] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 0] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:05,  3.11it/s]\n",
      "[Process 1] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 3] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 6] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:05,  3.14it/s]\n",
      "[Process 5] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 7] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 2] Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "[Process 6] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:03,  4.64it/s]\n",
      "[Process 0] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:03,  4.24it/s]\n",
      "[Process 4] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:05,  2.71it/s]\n",
      "[Process 6] Loading checkpoint shards:  18%|#7        | 3/17 [00:00<00:02,  5.21it/s]\n",
      "[Process 0] Loading checkpoint shards:  18%|#7        | 3/17 [00:00<00:03,  4.30it/s]\n",
      "[Process 1] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:06,  2.39it/s]\n",
      "[Process 3] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:06,  2.30it/s]\n",
      "[Process 4] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:04,  3.26it/s]\n",
      "[Process 6] Loading checkpoint shards:  24%|##3       | 4/17 [00:00<00:02,  4.82it/s]\n",
      "[Process 7] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:07,  2.11it/s]\n",
      "[Process 5] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:07,  2.04it/s]\n",
      "[Process 1] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:04,  3.03it/s]\n",
      "[Process 2] Loading checkpoint shards:   6%|5         | 1/17 [00:00<00:09,  1.62it/s]\n",
      "[Process 3] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:05,  2.65it/s]\n",
      "[Process 0] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:03,  3.67it/s]\n",
      "[Process 4] Loading checkpoint shards:  18%|#7        | 3/17 [00:00<00:04,  3.05it/s]\n",
      "[Process 6] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:02,  4.21it/s]\n",
      "[Process 5] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:05,  2.80it/s]\n",
      "[Process 7] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:07,  2.09it/s]\n",
      "[Process 1] Loading checkpoint shards:  18%|#7        | 3/17 [00:01<00:04,  2.95it/s]\n",
      "[Process 2] Loading checkpoint shards:  12%|#1        | 2/17 [00:00<00:06,  2.21it/s]\n",
      "[Process 0] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:03,  3.28it/s]\n",
      "[Process 3] Loading checkpoint shards:  18%|#7        | 3/17 [00:01<00:05,  2.71it/s]\n",
      "[Process 4] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:04,  2.99it/s]\n",
      "[Process 5] Loading checkpoint shards:  18%|#7        | 3/17 [00:01<00:04,  3.06it/s]\n",
      "[Process 6] Loading checkpoint shards:  35%|###5      | 6/17 [00:01<00:02,  3.71it/s]\n",
      "[Process 7] Loading checkpoint shards:  18%|#7        | 3/17 [00:01<00:06,  2.29it/s]\n",
      "[Process 2] Loading checkpoint shards:  18%|#7        | 3/17 [00:01<00:05,  2.43it/s]\n",
      "[Process 3] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:04,  2.84it/s]\n",
      "[Process 0] Loading checkpoint shards:  35%|###5      | 6/17 [00:01<00:03,  3.14it/s]\n",
      "[Process 1] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:04,  2.75it/s]\n",
      "[Process 4] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:04,  2.93it/s]\n",
      "[Process 5] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:04,  3.07it/s]\n",
      "[Process 6] Loading checkpoint shards:  41%|####1     | 7/17 [00:01<00:02,  3.48it/s]\n",
      "[Process 7] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:04,  2.71it/s]\n",
      "[Process 2] Loading checkpoint shards:  24%|##3       | 4/17 [00:01<00:05,  2.56it/s]\n",
      "[Process 3] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:04,  2.97it/s]\n",
      "[Process 5] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:03,  3.14it/s]\n",
      "[Process 0] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  3.09it/s]\n",
      "[Process 4] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:03,  2.96it/s]\n",
      "[Process 6] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:02,  3.12it/s]\n",
      "[Process 1] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:04,  2.61it/s]\n",
      "[Process 7] Loading checkpoint shards:  29%|##9       | 5/17 [00:01<00:04,  2.76it/s]\n",
      "[Process 3] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:03,  3.13it/s]\n",
      "[Process 5] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:03,  2.97it/s]\n",
      "[Process 0] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:03,  2.94it/s]\n",
      "[Process 2] Loading checkpoint shards:  29%|##9       | 5/17 [00:02<00:04,  2.64it/s]\n",
      "[Process 4] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  3.02it/s]\n",
      "[Process 6] Loading checkpoint shards:  53%|#####2    | 9/17 [00:02<00:02,  3.07it/s]\n",
      "[Process 1] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:04,  2.61it/s]\n",
      "[Process 3] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  3.18it/s]\n",
      "[Process 7] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:03,  2.88it/s]\n",
      "[Process 0] Loading checkpoint shards:  53%|#####2    | 9/17 [00:02<00:02,  2.98it/s]\n",
      "[Process 2] Loading checkpoint shards:  35%|###5      | 6/17 [00:02<00:04,  2.63it/s]\n",
      "[Process 4] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:03,  2.96it/s]\n",
      "[Process 5] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  2.84it/s]\n",
      "[Process 6] Loading checkpoint shards:  59%|#####8    | 10/17 [00:02<00:02,  2.96it/s]\n",
      "[Process 1] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  2.64it/s]\n",
      "[Process 7] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  2.91it/s]\n",
      "[Process 3] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:03,  2.84it/s]\n",
      "[Process 0] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  3.00it/s]\n",
      "[Process 4] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  3.00it/s]\n",
      "[Process 2] Loading checkpoint shards:  41%|####1     | 7/17 [00:02<00:03,  2.68it/s]\n",
      "[Process 5] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:03,  2.79it/s]\n",
      "[Process 1] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:03,  2.74it/s]\n",
      "[Process 6] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:02,  2.87it/s]\n",
      "[Process 7] Loading checkpoint shards:  47%|####7     | 8/17 [00:02<00:02,  3.02it/s]\n",
      "[Process 3] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  3.01it/s]\n",
      "[Process 0] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:01,  3.23it/s]\n",
      "[Process 4] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  3.05it/s]\n",
      "[Process 2] Loading checkpoint shards:  47%|####7     | 8/17 [00:03<00:03,  2.79it/s]\n",
      "[Process 5] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  2.79it/s]\n",
      "[Process 6] Loading checkpoint shards:  71%|#######   | 12/17 [00:03<00:01,  2.78it/s]\n",
      "[Process 7] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  2.89it/s]\n",
      "[Process 1] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  2.68it/s]\n",
      "[Process 3] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  2.96it/s]\n",
      "[Process 0] Loading checkpoint shards:  71%|#######   | 12/17 [00:03<00:01,  3.12it/s]\n",
      "[Process 4] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:02,  2.99it/s]\n",
      "[Process 5] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  2.93it/s]\n",
      "[Process 2] Loading checkpoint shards:  53%|#####2    | 9/17 [00:03<00:02,  2.81it/s]\n",
      "[Process 1] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  2.80it/s]\n",
      "[Process 3] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:01,  3.07it/s]\n",
      "[Process 6] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.77it/s]\n",
      "[Process 7] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  2.69it/s]\n",
      "[Process 0] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.98it/s]\n",
      "[Process 4] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  2.81it/s]\n",
      "[Process 5] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:01,  3.00it/s]\n",
      "[Process 1] Loading checkpoint shards:  65%|######4   | 11/17 [00:03<00:02,  2.93it/s]\n",
      "[Process 2] Loading checkpoint shards:  59%|#####8    | 10/17 [00:03<00:02,  2.77it/s]\n",
      "[Process 6] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:01,  2.91it/s]\n",
      "[Process 3] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  3.09it/s]\n",
      "[Process 7] Loading checkpoint shards:  65%|######4   | 11/17 [00:04<00:02,  2.71it/s]\n",
      "[Process 0] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:01,  2.89it/s]\n",
      "[Process 5] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  3.03it/s]\n",
      "[Process 4] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.77it/s]\n",
      "[Process 2] Loading checkpoint shards:  65%|######4   | 11/17 [00:04<00:02,  2.80it/s]\n",
      "[Process 6] Loading checkpoint shards:  88%|########8 | 15/17 [00:04<00:00,  2.93it/s]\n",
      "[Process 1] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  2.85it/s]\n",
      "[Process 3] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.94it/s]\n",
      "[Process 7] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  2.81it/s]\n",
      "[Process 0] Loading checkpoint shards:  88%|########8 | 15/17 [00:04<00:00,  2.90it/s]\n",
      "[Process 5] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.99it/s]\n",
      "[Process 2] Loading checkpoint shards:  71%|#######   | 12/17 [00:04<00:01,  2.91it/s]\n",
      "[Process 4] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:01,  2.74it/s]\n",
      "[Process 6] Loading checkpoint shards:  94%|#########4| 16/17 [00:04<00:00,  2.98it/s]\n",
      "[Process 1] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.80it/s]\n",
      "[Process 3] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:01,  2.89it/s]\n",
      "[Process 7] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  2.94it/s]\n",
      "[Process 0] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  2.91it/s]\n",
      "[Process 2] Loading checkpoint shards:  76%|#######6  | 13/17 [00:04<00:01,  3.12it/s]\n",
      "[Process 5] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:00,  3.06it/s]\n",
      "[Process 4] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  2.89it/s]\n",
      "[Process 1] Loading checkpoint shards:  82%|########2 | 14/17 [00:04<00:00,  3.00it/s]\n",
      "[Process 3] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  3.12it/s]\n",
      "[Process 6] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  2.91it/s]\n",
      "[Process 6] \n",
      "[Process 7] Loading checkpoint shards:  82%|########2 | 14/17 [00:05<00:01,  2.98it/s]\n",
      "[Process 5] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  3.12it/s]\n",
      "[Process 6] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.18it/s]\n",
      "[Process 2] Loading checkpoint shards:  82%|########2 | 14/17 [00:05<00:00,  3.15it/s]\n",
      "[Process 4] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  3.04it/s]\n",
      "[Process 6] \n",
      "\n",
      "[Process 0] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  2.71it/s]\n",
      "[Process 1] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  3.17it/s]\n",
      "[Process 3] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  3.30it/s]\n",
      "[Process 7] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  3.32it/s]\n",
      "[Process 0] \n",
      "[Process 5] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  3.55it/s]\n",
      "[Process 0] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.05it/s]\n",
      "[Process 2] Loading checkpoint shards:  88%|########8 | 15/17 [00:05<00:00,  3.47it/s]\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  3.68it/s]\n",
      "[Process 7] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  3.89it/s]\n",
      "[Process 4] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.25it/s]\n",
      "[Process 2] Loading checkpoint shards:  94%|#########4| 16/17 [00:05<00:00,  4.02it/s]\n",
      "[Process 3] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.45it/s]\n",
      "[Process 4] \n",
      "[Process 3] \n",
      "[Process 4] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.00it/s]\n",
      "[Process 5] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.78it/s]\n",
      "[Process 3] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.05it/s]\n",
      "[Process 4] \n",
      "\n",
      "[Process 5] \n",
      "[Process 1] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.93it/s]\n",
      "[Process 3] \n",
      "\n",
      "[Process 5] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.10it/s]\n",
      "[Process 1] \n",
      "[Process 5] \n",
      "\n",
      "[Process 7] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  4.05it/s]\n",
      "[Process 1] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.01it/s]\n",
      "[Process 7] \n",
      "[Process 1] \n",
      "\n",
      "[Process 7] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.01it/s]\n",
      "[Process 7] \n",
      "\n",
      "[Process 2] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  3.95it/s]\n",
      "[Process 2] \n",
      "[Process 2] Loading checkpoint shards: 100%|##########| 17/17 [00:05<00:00,  2.98it/s]\n",
      "[Process 2] \n",
      "\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 7.77 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "model_name = \"Qwen/Qwen3-32B\"\n",
    "tp_plan = {\n",
    "    \"model.layers.*.self_attn.q_proj\": \"colwise\",\n",
    "    \"model.layers.*.self_attn.k_proj\": \"colwise\",\n",
    "    \"model.layers.*.self_attn.v_proj\": \"colwise\",\n",
    "    \"model.layers.*.self_attn.o_proj\": \"rowwise\",\n",
    "    \"model.layers.*.mlp.up_proj\": \"colwise\",\n",
    "    \"model.layers.*.mlp.gate_proj\": \"colwise\",\n",
    "    \"model.layers.*.mlp.down_proj\": \"rowwise\",\n",
    "    \"lm_head\": \"colwise_rep\",\n",
    "}\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, tp_plan=tp_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3c400e-7e9b-4d62-8245-eb40ad9b1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "[Process 6] Device set to use cuda:6\n",
      "\n",
      "[Process 7] Device set to use cuda:7\n",
      "\n",
      "[Process 0] Device set to use cuda:0\n",
      "\n",
      "[Process 2] Device set to use cuda:2\n",
      "\n",
      "[Process 3] Device set to use cuda:3\n",
      "\n",
      "[Process 4] Device set to use cuda:4\n",
      "\n",
      "[Process 5] Device set to use cuda:5\n",
      "\n",
      "[Process 1] Device set to use cuda:1\n",
      "\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 0.58 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"Can I help\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bca728-c948-4d95-b09c-0dbe063ce1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "[Process 0] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 1] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 2] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 3] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 4] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 5] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 6] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 7] Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "[Process 1] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 2] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 3] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 4] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 5] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 6] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 7] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 0] Both `max_new_tokens` (=10) and `max_length`(=10) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "[Process 6] [{'generated_text': \"Can I help a solve？的Okay'm sorry, I'm\"}]\n",
      "[Process 7] [{'generated_text': \"Can I help my? 的\\nOkay'm here, I'm\"}]\n",
      "[Process 0] [{'generated_text': \"Can I help you? Yes的Yes'm sorry, I'm\"}]\n",
      "[Process 1] [{'generated_text': \"Can I help my find的\\n\\nCan'm sorry, I'm\"}]\n",
      "[Process 2] [{'generated_text': \"Can I help someone with的 I'm sorry, I'm\"}]\n",
      "[Process 3] [{'generated_text': \"Can I help you？的\\n\\nYes'm fine, I can\"}]\n",
      "[Process 4] [{'generated_text': \"Can I help you with翻译的Yes'm sorry, I'm\"}]\n",
      "[Process 5] [{'generated_text': \"Can I help you with \\n\\nYes'm very, I'm\"}]\n",
      "[Process 6] \n",
      "\n",
      "[Process 7] \n",
      "\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] \n",
      "\n",
      "[Process 2] \n",
      "\n",
      "[Process 3] \n",
      "\n",
      "[Process 4] \n",
      "\n",
      "[Process 5] \n",
      "\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 3.19 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "output = pipe(prompt, max_length=10, max_new_tokens=10)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cba49a-f230-40d3-bd67-00d7f405de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "[Process 0] hello\n",
      "[Process 1] hello\n",
      "[Process 2] hello\n",
      "[Process 3] hello\n",
      "[Process 4] hello\n",
      "[Process 5] hello\n",
      "[Process 6] hello\n",
      "[Process 7] hello\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] \n",
      "\n",
      "[Process 2] \n",
      "\n",
      "[Process 3] \n",
      "\n",
      "[Process 4] \n",
      "\n",
      "[Process 5] \n",
      "\n",
      "[Process 6] \n",
      "\n",
      "[Process 7] \n",
      "\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718a4ecf-a3a8-45a4-bebb-b9b893136251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 8 persistent processes...\n",
      "[MAIN] at 0:0.00000: Starting to send tasks to 8 workers\n",
      "\n",
      "[MAIN] at 0:0.00011: Task sent to worker 0\n",
      "\n",
      "[MAIN] at 0:0.00016: Task sent to worker 1\n",
      "\n",
      "[MAIN] at 0:0.00020: Task sent to worker 2\n",
      "\n",
      "[MAIN] at 0:0.00025: Task sent to worker 3\n",
      "\n",
      "[MAIN] at 0:0.00030: Task sent to worker 4\n",
      "\n",
      "[MAIN] at 0:0.00035: Task sent to worker 5\n",
      "\n",
      "[MAIN] at 0:0.00039: Task sent to worker 6\n",
      "\n",
      "[MAIN] at 0:0.00044: Task sent to worker 7\n",
      "\n",
      "[MAIN] at 0:0.00047: Starting result collection\n",
      "\n",
      "[Process 0] [DIAGNOSTIC] Process 0 at 0:4.61248: Received task, starting execution\n",
      "\n",
      "[Process 1] [DIAGNOSTIC] Process 1 at 0:4.60700: Received task, starting execution\n",
      "\n",
      "[Process 2] [DIAGNOSTIC] Process 2 at 0:4.60466: Received task, starting execution\n",
      "\n",
      "[Process 3] [DIAGNOSTIC] Process 3 at 0:4.60637: Received task, starting execution\n",
      "\n",
      "[Process 4] [DIAGNOSTIC] Process 4 at 0:4.59924: Received task, starting execution\n",
      "\n",
      "[Process 5] [DIAGNOSTIC] Process 5 at 0:4.59880: Received task, starting execution\n",
      "\n",
      "[Process 6] [DIAGNOSTIC] Process 6 at 0:4.59660: Received task, starting execution\n",
      "\n",
      "[Process 7] [DIAGNOSTIC] Process 7 at 0:4.59252: Received task, starting execution\n",
      "\n",
      "[Process 0] [DIAGNOSTIC] Process 0 at 0:4.61251: About to execute code\n",
      "\n",
      "[Process 1] [DIAGNOSTIC] Process 1 at 0:4.60707: About to execute code\n",
      "\n",
      "[Process 2] [DIAGNOSTIC] Process 2 at 0:4.60471: About to execute code\n",
      "\n",
      "[Process 3] [DIAGNOSTIC] Process 3 at 0:4.60640: About to execute code\n",
      "\n",
      "[Process 4] [DIAGNOSTIC] Process 4 at 0:4.59927: About to execute code\n",
      "\n",
      "[Process 5] [DIAGNOSTIC] Process 5 at 0:4.59886: About to execute code\n",
      "\n",
      "[Process 6] [DIAGNOSTIC] Process 6 at 0:4.59665: About to execute code\n",
      "\n",
      "[Process 7] [DIAGNOSTIC] Process 7 at 0:4.59256: About to execute code\n",
      "\n",
      "[Process 0] hello\n",
      "[Process 1] hello\n",
      "[Process 2] hello\n",
      "[Process 3] hello\n",
      "[Process 4] hello\n",
      "[Process 5] hello\n",
      "[Process 6] hello\n",
      "[Process 7] hello\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] \n",
      "\n",
      "[Process 2] \n",
      "\n",
      "[Process 3] \n",
      "\n",
      "[Process 4] \n",
      "\n",
      "[Process 5] \n",
      "\n",
      "[Process 6] \n",
      "\n",
      "[Process 7] \n",
      "\n",
      "[Process 0] [DIAGNOSTIC] Process 0 at 0:4.61259: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 1] [DIAGNOSTIC] Process 1 at 0:4.60720: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 2] [DIAGNOSTIC] Process 2 at 0:4.60484: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 3] [DIAGNOSTIC] Process 3 at 0:4.60646: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 4] [DIAGNOSTIC] Process 4 at 0:4.59934: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 5] [DIAGNOSTIC] Process 5 at 0:4.59897: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 6] [DIAGNOSTIC] Process 6 at 0:4.59683: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 7] [DIAGNOSTIC] Process 7 at 0:4.59265: Code execution completed in 0.000 seconds\n",
      "\n",
      "[Process 0] [DIAGNOSTIC] Process 0 at 0:4.61259: Sending result to output queue\n",
      "\n",
      "[Process 1] [DIAGNOSTIC] Process 1 at 0:4.60721: Sending result to output queue\n",
      "\n",
      "[Process 2] [DIAGNOSTIC] Process 2 at 0:4.60485: Sending result to output queue\n",
      "\n",
      "[Process 3] [DIAGNOSTIC] Process 3 at 0:4.60646: Sending result to output queue\n",
      "\n",
      "[Process 4] [DIAGNOSTIC] Process 4 at 0:4.59934: Sending result to output queue\n",
      "\n",
      "[Process 5] [DIAGNOSTIC] Process 5 at 0:4.59898: Sending result to output queue\n",
      "\n",
      "[Process 6] [DIAGNOSTIC] Process 6 at 0:4.59684: Sending result to output queue\n",
      "\n",
      "[Process 7] [DIAGNOSTIC] Process 7 at 0:4.59265: Sending result to output queue\n",
      "\n",
      "[MAIN] at 0:0.02641: Received result from worker 0 with process ID 0\n",
      "\n",
      "[MAIN] at 0:0.02657: Received result from worker 1 with process ID 1\n",
      "\n",
      "[MAIN] at 0:0.02663: Received result from worker 2 with process ID 2\n",
      "\n",
      "[MAIN] at 0:0.02668: Received result from worker 3 with process ID 3\n",
      "\n",
      "[MAIN] at 0:0.02672: Received result from worker 4 with process ID 4\n",
      "\n",
      "[MAIN] at 0:0.02677: Received result from worker 5 with process ID 5\n",
      "\n",
      "[MAIN] at 0:0.02681: Received result from worker 6 with process ID 6\n",
      "\n",
      "[MAIN] at 0:0.02687: Received result from worker 7 with process ID 7\n",
      "\n",
      "Successfully executed in all 8 processes\n",
      "Execution time: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 8 --debug\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923a8971-35af-4b12-810f-9f1ee80850b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter Distributed extension with persistent processes loaded.\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcff261-686f-477a-a75a-e72c7af9726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 2 persistent processes...\n",
      "[Process 0] Worker process 0 started with PID 2914640\n",
      "\n",
      "[Process 1] Worker process 1 started with PID 2914641\n",
      "\n",
      "Successfully executed in all 2 processes\n",
      "Execution time: 3.45 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 2\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ec3f74-bcd8-4a08-b7a0-5d9b7e99dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 2 persistent processes...\n",
      "[Process 0] <function pipeline at 0x70ea592858a0>\n",
      "[Process 1] <function pipeline at 0x720bf0fa58a0>\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] \n",
      "\n",
      "Successfully executed in all 2 processes\n",
      "Execution time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 2\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11750db6-dd7c-47cd-896e-3ed2c090ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 2 persistent processes...\n",
      "\n",
      "Execution interrupted by user. Sending interrupt to workers...\n",
      "Process 0 interrupted successfully.\n",
      "Process 1 interrupted successfully.\n",
      "Execution time: 1.12 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 2\n",
    "import time\n",
    "time.sleep(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9368547f-d097-47f0-a706-126d70fa46e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 2 persistent processes...\n",
      "[Process 0] /home/isaac/llm_server/.venv/lib/python3.12/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n",
      "\n",
      "[Process 1] /home/isaac/llm_server/.venv/lib/python3.12/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n",
      "\n",
      "[Process 0] Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "[Process 1] Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "[Process 1] Loading checkpoint shards:  25%|##5       | 1/4 [00:03<00:09,  3.01s/it]\n",
      "[Process 0] Loading checkpoint shards:  25%|##5       | 1/4 [00:03<00:09,  3.10s/it]\n",
      "[Process 0] Loading checkpoint shards:  50%|#####     | 2/4 [00:07<00:07,  3.60s/it]\n",
      "[Process 1] Loading checkpoint shards:  50%|#####     | 2/4 [00:07<00:07,  3.66s/it]\n",
      "[Process 1] Loading checkpoint shards:  75%|#######5  | 3/4 [00:11<00:03,  3.85s/it]\n",
      "[Process 0] Loading checkpoint shards:  75%|#######5  | 3/4 [00:11<00:03,  3.89s/it]\n",
      "[Process 0] Loading checkpoint shards: 100%|##########| 4/4 [00:13<00:00,  3.34s/it]\n",
      "[Process 0] \n",
      "[Process 0] Loading checkpoint shards: 100%|##########| 4/4 [00:13<00:00,  3.44s/it]\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] Loading checkpoint shards: 100%|##########| 4/4 [00:13<00:00,  3.37s/it]\n",
      "[Process 1] \n",
      "[Process 1] Loading checkpoint shards: 100%|##########| 4/4 [00:13<00:00,  3.46s/it]\n",
      "[Process 1] \n",
      "\n",
      "Successfully executed in all 2 processes\n",
      "Execution time: 48.45 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 2\n",
    "model2 = AutoModelForCausalLM.from_pretrained('Qwen/Qwen3-32B-AWQ', device_map=f'cuda:{__process_id__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6381a010-3b4c-47ae-85bf-e242511c32c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing execution across 2 persistent processes...\n",
      "[Process 0] Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 5120)\n",
      "    (layers): ModuleList(\n",
      "      (0-63): 64 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): WQLinear_GEMM(in_features=5120, out_features=8192, bias=False, w_bit=4, group_size=128)\n",
      "          (k_proj): WQLinear_GEMM(in_features=5120, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
      "          (v_proj): WQLinear_GEMM(in_features=5120, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
      "          (o_proj): WQLinear_GEMM(in_features=8192, out_features=5120, bias=False, w_bit=4, group_size=128)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): WQLinear_GEMM(in_features=5120, out_features=25600, bias=False, w_bit=4, group_size=128)\n",
      "          (up_proj): WQLinear_GEMM(in_features=5120, out_features=25600, bias=False, w_bit=4, group_size=128)\n",
      "          (down_proj): WQLinear_GEMM(in_features=25600, out_features=5120, bias=False, w_bit=4, group_size=128)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
      ")\n",
      "[Process 1] Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 5120)\n",
      "    (layers): ModuleList(\n",
      "      (0-63): 64 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): WQLinear_GEMM(in_features=5120, out_features=8192, bias=False, w_bit=4, group_size=128)\n",
      "          (k_proj): WQLinear_GEMM(in_features=5120, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
      "          (v_proj): WQLinear_GEMM(in_features=5120, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
      "          (o_proj): WQLinear_GEMM(in_features=8192, out_features=5120, bias=False, w_bit=4, group_size=128)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): WQLinear_GEMM(in_features=5120, out_features=25600, bias=False, w_bit=4, group_size=128)\n",
      "          (up_proj): WQLinear_GEMM(in_features=5120, out_features=25600, bias=False, w_bit=4, group_size=128)\n",
      "          (down_proj): WQLinear_GEMM(in_features=25600, out_features=5120, bias=False, w_bit=4, group_size=128)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((5120,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=5120, out_features=151936, bias=False)\n",
      ")\n",
      "[Process 0] \n",
      "\n",
      "[Process 1] \n",
      "\n",
      "Successfully executed in all 2 processes\n",
      "Execution time: 29.26 seconds\n"
     ]
    }
   ],
   "source": [
    "%%distribute 2\n",
    "print(model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
